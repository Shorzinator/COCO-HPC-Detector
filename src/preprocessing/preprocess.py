import os

import numpy as np
from PIL import Image
from pycocotools.coco import COCO
from tensorflow import keras

from src.utility.path_utils import get_path_from_root

# Constants
ANNOTATION_FILE_TRAIN = get_path_from_root("data", "coco", "annotations", "train&val", "instances_train2014.json")
ANNOTATION_FILE_VAL = get_path_from_root("data", "coco", "annotations", "train&val", "instances_val2014.json")
IMAGE_DIR = get_path_from_root("data", "coco", "images", "train")
MASK_DIR_TRAIN = get_path_from_root("data", "mask", "train")
MASK_DIR_VAL = get_path_from_root("data", "mask", "val")
TARGET_SIZE = (128, 128)  # Example target size for resizing images and masks

# Initialize COCO API
coco_train = COCO(ANNOTATION_FILE_TRAIN)
coco_val = COCO(ANNOTATION_FILE_VAL)


# Function to filter and load image IDs based on categories
def filter_images(coco, category_names):
    catIds = coco.getCatIds(catNms=category_names)
    imgIds = coco.getImgIds(catIds=catIds)
    return imgIds


def generate_masks(coco, imgIds, mask_dir, image_dir, category_names):
    # Ensure the mask directory exists
    os.makedirs(mask_dir, exist_ok=True)

    for img_id in imgIds:
        # Set the file path for the mask
        mask_file = os.path.join(mask_dir, f"COCO_train2014_{img_id:012d}.jpg")

        annIds = coco.getAnnIds(imgIds=img_id, catIds=coco.getCatIds(catNms=category_names), iscrowd=0)
        anns = coco.loadAnns(annIds)

        if anns:
            # Generate the mask by combining the individual instance masks
            mask = coco.annToMask(anns[0])
            for i in range(1, len(anns)):
                mask |= coco.annToMask(anns[i])

            # Convert the mask to an image and save it
            mask_img = Image.fromarray(mask * 255, mode='L')
            mask_img = mask_img.resize(TARGET_SIZE)
            mask_img.save(mask_file)

            # Process and save the corresponding image
            img_info = coco.loadImgs(img_id)[0]
            img_path = os.path.join(image_dir, img_info['file_name'])
            image = Image.open(img_path)
            resized_image = image.resize(TARGET_SIZE)
            resized_image.save(os.path.join(image_dir, f"COCO_train2014_{img_id:012d}.jpg"))


class CustomDataGenerator(keras.utils.Sequence):
    def __init__(self, coco, imgIds, images_path, masks_path, batch_size):
        self.coco = coco
        self.imgIds = imgIds
        self.images_path = images_path
        self.masks_path = masks_path
        self.batch_size = batch_size

    def __len__(self):
        return int(np.ceil(len(self.imgIds) / self.batch_size))

    def __getitem__(self, idx):
        batch_imgIds = self.imgIds[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_images = []
        batch_masks = []

        for img_id in batch_imgIds:
            image_filename = f"COCO_train2014_{img_id:012d}.jpg"
            img_path = os.path.join(self.images_path, image_filename)
            mask_path = os.path.join(self.masks_path, image_filename)

            image = Image.open(img_path).resize(TARGET_SIZE)
            mask = Image.open(mask_path).resize(TARGET_SIZE)

            batch_images.append(np.array(image) / 255.0)
            batch_masks.append(np.array(mask) / 255.0)

        return np.array(batch_images), np.array(batch_masks)


def validate_images_and_masks(generator):
    """
    Validate the shapes and alignment of preprocessed images and masks generated by the provided generator.

    Args:
        generator (CustomDataGenerator): Instance of the CustomDataGenerator class.
    """
    for i in range(len(generator)):
        batch_images, batch_masks = generator[i]

        for image, mask in zip(batch_images, batch_masks):
            if image.shape[:2] != mask.shape[:2]:
                print(f"Mismatch in image and mask dimensions: {image.shape} vs {mask.shape}")
            else:
                print(f"Image and mask dimensions match: {image.shape}")


# Main process
if __name__ == "__main__":
    train_imgIds = filter_images(coco_train, ['person'])
    val_imgIds = filter_images(coco_val, ['person'])

    # Ensure mask directories exist
    os.makedirs(MASK_DIR_TRAIN, exist_ok=True)
    os.makedirs(MASK_DIR_VAL, exist_ok=True)

    # Generate masks for training and validation sets
    generate_masks(coco_train, train_imgIds, MASK_DIR_TRAIN, IMAGE_DIR, ['person'])
    generate_masks(coco_val, val_imgIds, MASK_DIR_VAL, IMAGE_DIR, ['person'])

    # Initialize the data generators
    train_generator = CustomDataGenerator(coco_train, train_imgIds, IMAGE_DIR, MASK_DIR_TRAIN, batch_size=8)
    val_generator = CustomDataGenerator(coco_val, val_imgIds, IMAGE_DIR, MASK_DIR_VAL, batch_size=8)

    # Validate the shapes and alignment of preprocessed images and masks
    print("Validating Training Data...")
    validate_images_and_masks(train_generator)

    print("Validating Validation Data...")
    validate_images_and_masks(val_generator)
